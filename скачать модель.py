import os

# ==================== –ö–≠–® ====================
MODEL_PATH = "/mnt/807EB5FA7EB5E954/soft/Virtual_machine/linux must have/python_linux/work/cache"
os.environ["HF_HOME"] = MODEL_PATH
os.environ["HUGGINGFACE_HUB_CACHE"] = os.path.join(MODEL_PATH, "hub")
os.environ["TRANSFORMERS_CACHE"] = os.path.join(MODEL_PATH, "transformers")
# pip install torch==2.8.0 torchaudio==2.8.0
# ==================== –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å ====================
# print("–ó–∞–≥—Ä—É–∂–∞–µ–º GigaAM-v3 (e2e_rnnt)...")
from transformers import AutoModel
revision = "e2e_rnnt"  # can be any v3 model: ssl, ctc, rnnt, e2e_ctc, e2e_rnnt
try:

  model = AutoModel.from_pretrained("ai-sage/GigaAM-v3",
                                    revision="e2e_rnnt",  # –∏–ª–∏ "rnnt" ‚Äî –æ–±–µ —Ä–∞–±–æ—Ç–∞—é—Ç,
                                    device_map="cpu", trust_remote_code=True, )  # ‚Üê –±–µ–∑ —ç—Ç–æ–≥–æ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –±—É–¥–µ—Ç
  message = model.transcribe("/mnt/807EB5FA7EB5E954/soft/Virtual_machine/linux must have/python_linux/work/temp.wav")
  print(message)
except Exception as e:
 print(e)
print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")



# Audio embeddings
# model_name = "v3_ssl"       # Options: `v1_ssl`, `v2_ssl`, `v3_ssl`
# model = gigaam.load_model(model_name)
# transcription = model.transcribe("temp.wav")
# print(embedding)
from my_gaam import GigaASR
#
# asr = GigaASR("/mnt/807EB5FA7EB5E954/soft/Virtual_machine/linux must have/python_linux/work/cache/gigaam/v2_rnnt.ckpt")
# print(asr.transcribe("/mnt/807EB5FA7EB5E954/soft/Virtual_machine/linux must have/python_linux/work/temp.wav"))

# import gigaam
# model_name = "v3_e2e_rnnt"  # Options: any model version with suffix `_ctc` or `_rnnt`
# model = gigaam.load_model(model_name)
# # ASR
# transcription = model.transcribe("/mnt/807EB5FA7EB5E954/soft/Virtual_machine/linux must have/python_linux/work/temp.wav")
# print(transcription)
# #







# import os
# import time
# from pathlib import Path
# from faster_whisper import WhisperModel
# from huggingface_hub import snapshot_download
#
#
# def monitor_download(model_name, download_dir):
#  print(f"üì• –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {model_name}")
#
#  # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
#  Path(download_dir).mkdir(parents=True, exist_ok=True)
#
#  # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
#  snapshot_download(
#   repo_id=model_name,
#   local_dir=download_dir,
#   local_dir_use_symlinks=False,
#   resume_download=True
#  )
#
#  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
#  total_size = sum(f.stat().st_size for f in Path(download_dir).rglob('*') if f.is_file())
#  print(f"üìä –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: {total_size / (1024 ** 3):.2f} GB")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
# model_name = "bzikst/faster-whisper-large-v3-russian"
# download_path = "./my_whisper_model"
# monitor_download(model_name, download_path)
#
# print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –≤ –ø–∞–º—è—Ç—å...")
# model = WhisperModel(
#  download_path,
#  device="cpu",
#  compute_type="int8"
# )
# # ==================== –ó–∞–ø—É—Å–∫ ====================
# audio_path = "temp.wav"
# transcription = model.transcribe(audio_path)
# print(transcription)
#
