# Импорт необходимых библиотек
# Укажите путь к вашей модели
# model_path = "/mnt/807EB5FA7EB5E954/soft/Virtual_machine/linux must have/python_linux/work/cache/model-q4_K.gguf"

import sys
import os
import re
import contextlib

from llama_cpp import Llama

# Укажите путь к модели Meta-Llama-3.1-8B-Instruct (GGUF q4_K)
model_path = "/mnt/807EB5FA7EB5E954/soft/Virtual_machine/linux must have/python_linux/work/cache/meta-llama-3.1-8b-instruct-q4_k_m.gguf"  # Замени на свой путь!

# Загружаем модель один раз
llm = Llama(
 model_path=model_path,
 n_ctx=8192,  # Большой контекст для Llama 3.1 — хватит для длинных текстов
 n_threads=4,  # Кол-во CPU-ядер; увеличь, если нужно
 n_gpu_layers=35,  # Если GPU: разгружает на GPU (0 для CPU only)
 verbose=False  # Без лишнего лога
)


def fix_text(text: str) -> str:
 """
 Исправляет текст от распознавания речи на русском: звуки (р↔л, ш↔с/х, ж↔з/г, з↔с/дз, щ↔ш/сч),
 грамматику (падежи, склонения, род, число). Возвращает ТОЛЬКО исправленный текст.
 Адаптировано для Llama 3.1 Instruct.
 """
 prompt = f"""<|begin_of_text|><|start_header_id|>system<|end_header_id|>

Ты — эксперт по исправлению текстов, полученных от систем распознавания речи на русском языке. У меня проблемы с дикцией из-за ДЦП: плохо произносятся звуки "р" (часто заменяется на "л" или пропускается), "л" (искажается), "ш" (может звучать как "с" или "х"), "ж" (как "з" или "г"), "з" (как "с" или "дз"), "щ" (как "ш" или "сч"). Из-за этого слова искажаются, например: "работа" может стать "лабода", "школьник" — "скольник", "жизнь" — "зиснь". Также бывают ошибки в грамматике: неправильные падежи (например, "в дом" вместо "в доме"), склонения (окончания слов), роде, числе и предложениях (смешанные слова или фразы).

Твоя задача: 
1. Прочитай предоставленный текст как "грязный" вывод распознавания речи.
2. Исправь орфографию, учитывая типичные замены звуков (р↔л, ш↔с/х, ж↔з/г, з↔с/дз, щ↔ш/сч). Предполагай, что текст близок к реальному смыслу, но искажён произношением.
3. Исправь грамматику: подбери правильные падежи, склонения, род, число, времена глаголов. Сделай текст coherentным и естественным на русском.
4. Если текст неоднозначен, выбери наиболее логичный вариант (предполагай повседневный контекст: разговор о жизни, работе, семье или хобби).
5. Ответь ТОЛЬКО исправленным текстом, без лишних объяснений, кавычек, скобок. Если оригинал слишком искажён, добавь в конце: [Возможная интерпретация].<|eot_id|><|start_header_id|>user<|end_header_id|>

Текст: {text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"""

 output = llm(
  prompt,
  max_tokens=512,  # Достаточно для исправления фразы
  temperature=0.0,  # Детерминированный вывод
  top_p=0.9,
  stop=["<|eot_id|>", "</s>"],  # Стоп-токены для Llama 3.1
  echo=False  # Не повторять промпт в выводе
 )

 # Извлекаем чистый ответ (после assistant)
 response = output["choices"][0]["text"].strip()
 # Убираем [Возможная интерпретация], если есть, или возвращаем как есть
 if '[Возможная интерпретация]' in response:
  response = response.split('[Возможная интерпретация]')[0].strip()
 return response


# Пример использования
if __name__ == "__main__":
 original = "я иду в лабоду потуми жени скольнику"  # Твой пример
 corrected = fix_text(original)
 print("Оригинал:", original)
 print("Исправлено:", corrected)